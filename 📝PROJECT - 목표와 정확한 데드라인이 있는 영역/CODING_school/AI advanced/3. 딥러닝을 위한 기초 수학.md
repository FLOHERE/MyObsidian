## 1. 일차함수, 기울기와 y절편
- 함수 : 두 집합 사이의 관계를 설명하는 수학 개념
	- x가 변함 -> y는 어떤 규칙으로 변하는지 나타냄
	- $y = f(x)$
- 일차 함수 : y가 x에 관한 일차식으로 표현된 경우
	- $y = ax + b (a!=0)$
		- y : 출력
		- ax + b : 입력
		- a는 0이 아니어야 한다..
	- a : 기울기
		- 기울기 : 기울어진 정도
		- x값이 증가할때 y값이 어느정도 증가하는지에 따라 그래프의 기울기 a가 정해진다.
	- b : 절편
		- 그래프가 축과 만나는 지점
		- y 절편 = b

![[Pasted image 20250419212547.png]]

- 딥러닝을 설명하는 가장 간단한 표현 : x가 주어지고 원하는 y값이 있을때 적절한 a와 b를 찾는것

## 2. 이차함수와 최솟값
- 이차 함수 : y가 x에 관한 이차식으로 표현되는 경우
	- $y = ax^3$
		- a는 0이 아닐때
	- 포물선 모양

![[Pasted image 20250419212841.png]]

>[!note] 최솟값을 찾기 위해 무엇을 사용할까?
>미분, 기울기 사용

- $y = ax^2$ 그래프를 x축 방향으로 p만큼, y축 방향으로 q 만큼평행이동 
  -> 점 p와 q를 꼭짓점으로 하는 포물선이 된다. 
	- **최솟값** : 포물선의 맨 아래에 위치한 지점

![[Pasted image 20250419213157.png]]

- 최소 제곱법 공식 사용 -> 최솟값 구할수 있음 
	- but!! 딥러닝을 실제로 실행할때는 사용 못함
		why ? => 최소 제곱법을 위해 꼭 필요한 조건을 몰라서;;
	- 따라서 **미분과 기울기 이용**

## 3. 미분, 순간 변화율과 기울기
- 딥러닝은 결국 일차 함수의 a와 b 값을 구하는것
	- a,b값 = 2차 함수포물선의 **최솟값** 구하는것
	- 최솟값은 또 어떻게 구해? : **미분으로**

- ex_) $y = x^2$ 이라는 그래프가 있다고 해보자. x축에 있는 한 점에 a에 대응하는 y의 값은 $a^2$ 이다.
	이때, a가 오른쪽이나 왼쪽으로 이동하면?
	=> y도 같이 조금씩 움직임
	
	만약, a가 0에 가까울 만큼 움직였다면???
	=> y의 값 또한 미세하게 변화함(실제로 움직이는 것이 아니라 방향만 드러내는 정도의 순간적인 변화)

- 순간 변화율 : 어느 쪽을 향하는 방향성을 지니고 있으므로, 이 방향을 따라 직선을 길게 그려 주면, 그래프와 맞닿은 접선이 그려진다.
	- 이 선이 바로 이 점에서의 **기울기**가 된다.
	- x가 0이면 y도 0이 되어야 한다.(기울기 0)
		- _x축과 평행한 직선으로 그어질 때가 바로 그래프에서 최솟값인 지점_
	- _미분한다 = 순간 변화율을 구한다_
		- 미분 계수 : 어느 순간에 어떤 변화가 일어나고 있는지 숫자로 나타낸것
			- **미분계수 = 기울기**

![[Pasted image 20250419214051.png]]

- 순간 변화율을 구하는 방법
	- ex_)어떤 함수 $f(x)$가 주어졌을때, 함수에 x축 위의 두 실수 a,b를 대입 
	  -> 두 점 A,B는 그림과 같이 각각 $A(a, f(a)), B(b, f(b))$에 해당하는곳에 표시됨
	- 델타(**Δ**) : 변화량을 나타내는 기호

![[Pasted image 20250419223004.png]]

![[Pasted image 20250419223130.png]]

- A와 B를 지나는 직선의 기울기 : $\frac{x값의 증가량}{y값의 증가량}$
	- AB의 기울기 = A와 B사이의 평균 변화율

![[Pasted image 20250419223440.png]]

- 순간 변화율(우리가 구해야 하는거) : x의 증가량이 0에 가까울 만큼 아주 작을때의 순간적인 기울기를 의미
	- 여기서 $lim$ 는x의 증가량이 0에 가까울 만큼 작을때 라는 뜻
	- 기울기 = $\frac {x값의 증가량} {y값의 증가량}$
	- 순간 기울기 : $lim \frac{x값의 증가량}{y값의 증가량}$ = $lim \frac{Δx}{Δy} = \frac{dx}{dy}$
- x의 순간 기울기 : 2차 함수에서 가장 기울기가 작은 값을 찾기 위함
	- 왜? : **loss(손실) 함수**를 찾기 위해 미분 사용
- 2차 함수 => 미분 => x의 순간 변화율

![[Pasted image 20250419223632.png]]

![[Pasted image 20250419224823.png]]

- 미분의 기본 공식
	1. $f(x) = x$ 일때 $f'(x) = 1$
	2. $f(x) = a$에서 $a$가 상수일때 $f'(x) = 0$
	3. $f(x) = ax$ 에서 $a$가 상수일때 $f'(x) = a$

## 4 편미분(partial)
- 미분과 편미분 모두 '미분하라' 는 의미에서는 다를 바가 없다.
- 편미분 : 우리가 원하는 한가지 변수만 미분하고 그 외에는 모두 상수로 취급하는 것
- $f(x,y) = x^2 + yx + a$ (a는 상수)
	- 변수가 x,y로 두개
	- 둘중 하나 미분해야 하므로 편미분 사용

![[Pasted image 20250419225343.png]]

- x에 관해 미분하라 : $\frac{∂f}{∂x}$

![[Pasted image 20250419231346.png]]

## 5. 지수와 지수 함수
- 지수 : $a^n$
- 지수 함수 : 변수 x가 지수 자리에 있는 경우 의미
	- $y = a^x$ (a != 1, a>0)

![[Pasted image 20250419231635.png]]

## 6. 시그모이드 함수
- 딥러닝 내부 : 입력받은 신호를 얼마나 출력할지 계산하는 과정 반복
- 활성화 함수 : 출력값으로 얼마나 내보낼지 계산하는 함수
	- 시그모이드 함수 : 지수 함수에서 밑 값이 자연 상수($e$)인 함수
		- 자연상수 $e$ : 파이처럼 수학에서 중요하게 사용되는 무리수(2.718281828...)
		- 자연 상수$e$가 지수 함수에 포함되어 분모에 들어가면 시그모이드 함수가 됨
		- $f(x) = \frac{1}{1+e^-x}$ : 분모는 무한대, f(x)의 x 값은 0~1
			- 무한대인 값이 입출력되는것.

![[Pasted image 20250419232114.png]]

- x가 큰값을 가지면 f(x)는 1에 가까워짐
- x가 작은 값을 가지면 f(x)는 0에 가까워짐
- S자 형태로 그려지는 이 함수의 속성은 **0 또는 1**
	- **두개중 하나의 값을 고를때 유용하다.**

## 7. 로그와 로그 함수
- 로그를 이해하려면 먼저 지수부터 이해해야 합니다. a를 x만큼 거듭제곱한 값이 b라고 할때 이를 식으로 나타내면 다음과 같습니다.
	- $a^x = b$
- 이때, a,b는 아는데 x를 모른다고 할때 x를 구하는 방법
	- log 사용
	- $a^x = b$ >>>> $x$ = $\log_a b$
- 로그함수는 지수함수의 역함수 관계다.
	- 역함수 : x와 y를 서로 바꾸어 가지는 함수
	- 로그 함수 형태 : $y = \log_a x$
	- $y = x$에 대해 대칭인 선으로 나타남

![[Pasted image 20250419233011.png]]

![[Pasted image 20250419233037.png]]

![[Pasted image 20250419233235.png]]

![[Pasted image 20250419233253.png]]

![[Pasted image 20250419233317.png]]

>[!note] 그럼 왜 억지로 2차함수 그래프로 만드는거임?
>- loss function(오차값)이 가장 작을때의 값을 구하기 위함.
>- loss 값 = $y-ŷ$  (실제값 - 예측값)

![[Pasted image 20250419233658.png]]

